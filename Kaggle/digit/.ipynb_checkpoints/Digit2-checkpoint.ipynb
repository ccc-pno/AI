{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一些超参数\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "learning_rate = 0.01\n",
    "epoches = 3\n",
    "lr = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (42000, 785)\n",
      "train_set.shape: (33600, 785)\n",
      "val_set.shape: (8400, 785)\n"
     ]
    }
   ],
   "source": [
    "# 准备训练、验证数据\n",
    "def train_val_split(train='train.csv',train_file='train_set.csv',val_file='val_set.csv'):\n",
    "    train_data = pd.read_csv(train)\n",
    "    train_set, val_set = train_test_split(train_data, random_state=666, test_size=0.2)\n",
    "    train_set.to_csv(train_file, index=False)\n",
    "    val_set.to_csv(val_file, index=False)\n",
    "    print('train_data.shape:',train_data.shape)\n",
    "    print('train_set.shape:',train_set.shape)\n",
    "    print('val_set.shape:',val_set.shape)\n",
    "\n",
    "train_val_split(train='train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理、读取数据\n",
    "def transform(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))   #三个颜色通道的平均值，三个颜色通道的标准差\n",
    "#      #transforms.Flip()  #旋转\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "class MyMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self,datatxt,train=True,transform=transform,target_trainform=None):\n",
    "        self.data = pd.read_csv(datatxt)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.X = self.data.iloc[:,1:]\n",
    "            self.X = np.array(self.X)\n",
    "            self.y = self.data.iloc[:,0]\n",
    "            self.y = np.array(self.y)\n",
    "        else:\n",
    "            self.X=self.data\n",
    "            self.X=np.array(self.X)\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        im = torch.tensor(self.X[index],dtype=torch.float)\n",
    "        if self.transform is not None:\n",
    "            im=self.transform(im)\n",
    "            im=im.reshape([1,28,28])\n",
    "            if self.train:\n",
    "                label=torch.tensor(self.y[index],dtype=torch.long)\n",
    "                return im,label\n",
    "            else:\n",
    "                return im\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# 使用ImageFolder去读取，返回后的数据路径和标签对应起来\n",
    "# all_dataset = datasets.ImageFolder('../data/amazon/images', transform=data_transform)\n",
    "\n",
    "# 使用random_split实现数据集的划分，lengths是一个list，按照对应的数量返回数据个数。\n",
    "# 这儿需要注意的是，lengths的数据量总和等于all_dataset中的数据个数，这儿不是按比例划分的\n",
    "# train, test, valid = torch.utils.data.random_split(dataset= all_dataset, lengths=[2000, 417, 400])\n",
    "    \n",
    "X_train = MyMNIST(datatxt='train_set.csv',train=True,transform=transform)\n",
    "X_val = MyMNIST(datatxt='val_set.csv',train=True,transform=transform)\n",
    "X_test  = MyMNIST(datatxt='test.csv',train=False,transform=transform)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(X_train,batch_size=64,shuffle=True)\n",
    "val_data = torch.utils.data.DataLoader(X_val, batch_size=64, shuffle=False)\n",
    "test_data = torch.utils.data.DataLoader(X_test, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'show_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a535e4c20a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'show_batch'"
     ]
    }
   ],
   "source": [
    "X_train.show_batch(row=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "examples = enumerate(train_data)\n",
    "batch_idx, [example_data, example_targets] = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "class LeNet_simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_simple,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # (N=64,C=1,H=28,W=28)\n",
    "            nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3,padding=1),\n",
    "            # (N=64,C=6,H=28,W=28)\n",
    "            nn.MaxPool2d(2,2)\n",
    "            # (N=64,C=6,H=14,W=14)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,padding=0),\n",
    "            # (N=64,C=16,H=10,W=10)\n",
    "            nn.MaxPool2d(2,2)\n",
    "            # (N=64,C=16,H=5,W=5)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(400,120),\n",
    "            nn.Linear(120,84),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "data: tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])\n",
      "Label: tensor([5, 4, 6, 8, 1, 1, 9, 1, 9, 2, 9, 4, 7, 5, 5, 0, 9, 8, 7, 3, 2, 6, 7, 5,\n",
      "        3, 2, 2, 0, 3, 5, 4, 8, 1, 5, 6, 6, 3, 3, 4, 4, 0, 3, 4, 9, 0, 2, 9, 7,\n",
      "        7, 3, 5, 5, 7, 7, 2, 2, 9, 4, 7, 0, 6, 9, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# 批量读取\n",
    "for i,traindata in enumerate(train_data):\n",
    "    print('i:',i)\n",
    "    Data,Label=traindata\n",
    "    print('data:',Data)\n",
    "    print('Label:',Label)\n",
    "    break\n",
    "\n",
    "# 迭代\n",
    "dataiter=iter(train_data)\n",
    "imgs,labels=next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "第100次：Loss：0.30787381529808044 ; Accuracy：0.90625\n",
      "第200次：Loss：0.3105652928352356 ; Accuracy：0.890625\n",
      "第300次：Loss：0.2055513709783554 ; Accuracy：0.90625\n",
      "第400次：Loss：0.3453071117401123 ; Accuracy：0.90625\n",
      "第500次：Loss：0.07642819732427597 ; Accuracy：0.96875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-21e062a84393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#         with torch.no_grad():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mval_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Accuracy(out,labels):\n",
    "    correct=0.0\n",
    "    total=0.0\n",
    "    _,predicted = torch.max(out.data, 1)\n",
    "    correct += (predicted==labels).sum()\n",
    "    total += labels.size(0)\n",
    "    accuracy = correct/total\n",
    "    return accuracy\n",
    "\n",
    "# 初始化\n",
    "# 检测是否有可用的GPU, 有则使用, 否则使用CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = LeNet_simple()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr,betas=(0.9,0.99))\n",
    "i=0\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(1):\n",
    "#     train, valid = get_k_fold_data(10,epoch,train_data,None)\n",
    "    train_loss=[]\n",
    "    accuracy=0.\n",
    "    correct=0.\n",
    "    total=0.\n",
    "    \n",
    "    #动态修改参数学习率\n",
    "    if epoch%5==0:\n",
    "        optimizer.param_groups[0]['lr']*=0.1\n",
    "        \n",
    "    net.train()\n",
    "    for j,mini_batch in enumerate(train_data):\n",
    "        \"\"\"训练\"\"\"\n",
    "        # 将数据copy到GPU上\n",
    "        imgs,labels=mini_batch\n",
    "        imgs=imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向传播\n",
    "        out = net(imgs)\n",
    "        loss = criterion(out,labels)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 输出信息\n",
    "        i+=1\n",
    "        accuracy=Accuracy(out,labels)\n",
    "        if i%100==0:\n",
    "            print(\"第{}次：Loss：{} ; Accuracy：{}\".format(i,loss,accuracy))\n",
    "            train_loss.append((i,loss))\n",
    "    \n",
    "    net.eval()\n",
    "    for j,mini_batch in enumerate(val_data):\n",
    "        \"\"\"验证\"\"\"\n",
    "#         with torch.no_grad():\n",
    "        imgs,labels = mini_batch\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        val_out = net(imgs)\n",
    "        val_loss = criterion(val_out,labels)\n",
    "        accuracy = Accuracy(val_out,labels)\n",
    "    \n",
    "    # 保存loss的数据与epoch数值\n",
    "    writer.add_scalar('训练损失值', loss, epoch)\n",
    "    writer.add_scalar('验证损失值', val_loss, epoch)\n",
    "                \n",
    "    print(\"准确度为{}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboardX\n",
    "\n",
    "# 实例化SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "import torchvision\n",
    "#实例化SummaryWriter, 并指明日志存放路径。在当前目录没有logs目录将自动创建。\n",
    "writer = SummaryWriter(log_dir=r'C:\\Users\\Administrator\\Desktop\\Kaggle\\digit\\logs')\n",
    "#调用实例\n",
    "input = torch.rand(64, 1, 28, 28)\n",
    "with SummaryWriter(log_dir=r'C:\\Users\\Administrator\\Desktop\\Kaggle\\digit\\logs',comment='net') as w:\n",
    "    w.add_graph(net, (input, ))\n",
    "\n",
    "# import os\n",
    "# os.system(r'tensorboard --logdir=\\'C:\\Users\\Administrator\\Desktop\\Kaggle\\digit\\logs\\' --port 6006')\n",
    "\n",
    "#关闭writer\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in net._modules.items():\n",
    "    print(name)\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
