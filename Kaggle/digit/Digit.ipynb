{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (42000, 785)\n",
      "train_set.shape: (33600, 785)\n",
      "val_set.shape: (8400, 785)\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "df_train.shape\n",
    "def train_val_split(train='train.csv',train_file='train_set.csv',val_file='val_set.csv'):\n",
    "    train_data = pd.read_csv(train)\n",
    "    train_set, val_set = train_test_split(train_data, random_state=666, test_size=0.2)\n",
    "    train_set.to_csv(train_file, index=False)\n",
    "    val_set.to_csv(val_file, index=False)\n",
    "    print('train_data.shape:',train_data.shape)\n",
    "    print('train_set.shape:',train_set.shape)\n",
    "    print('val_set.shape:',val_set.shape)\n",
    "\n",
    "train_val_split(train='train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化\n",
    "def transform(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))   #三个颜色通道的平均值，三个颜色通道的标准差\n",
    "#      #transforms.Flip()  #旋转\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "class MyMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self,datatxt,train=True,transform=transform,target_trainform=None):\n",
    "        self.data = pd.read_csv(datatxt)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.X = self.data.iloc[:,1:]\n",
    "            self.X = np.array(self.X)\n",
    "            self.y = self.data.iloc[:,0]\n",
    "            self.y = np.array(self.y)\n",
    "        else:\n",
    "            self.X=self.data\n",
    "            self.X=np.array(self.X)\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        im = torch.tensor(self.X[index],dtype=torch.float)\n",
    "        if self.transform is not None:\n",
    "            im=self.transform(im)\n",
    "            im=im.reshape([1,28,28])\n",
    "            if self.train:\n",
    "                label=torch.tensor(self.y[index],dtype=torch.long)\n",
    "                return im,label\n",
    "            else:\n",
    "                return im\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "X_train = MyMNIST(datatxt='train_set.csv',train=True,transform=transform)\n",
    "X_val = MyMNIST(datatxt='val_set.csv',train=True,transform=transform)\n",
    "X_test  = MyMNIST(datatxt='test.csv',train=False,transform=transform)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(X_train,batch_size=64,shuffle=True)\n",
    "val_data = torch.utils.data.DataLoader(X_val, batch_size=64, shuffle=False)\n",
    "test_data = torch.utils.data.DataLoader(X_test, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyMNIST at 0x23e05b5df88>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       " \n",
       " \n",
       "         [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]),\n",
       " tensor([7, 1, 3, 9, 9, 6, 0, 2, 7, 2, 7, 7, 0, 5, 4, 3, 9, 4, 8, 3, 7, 6, 6, 3,\n",
       "         7, 0, 0, 7, 2, 3, 9, 1, 2, 9, 4, 8, 0, 0, 2, 2, 2, 0, 1, 6, 9, 3, 1, 9,\n",
       "         1, 3, 2, 5, 2, 3, 0, 9, 9, 3, 3, 0, 4, 2, 2, 7])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(val_data) #随机加载一个mini batch\n",
    "dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第100次：Loss：0.2752797305583954 ; Accuracy：0.921875\n",
      "第200次：Loss：0.18505626916885376 ; Accuracy：0.9375\n",
      "第300次：Loss：0.07753101736307144 ; Accuracy：0.984375\n",
      "第400次：Loss：0.09379924088716507 ; Accuracy：0.953125\n",
      "第500次：Loss：0.13330043852329254 ; Accuracy：0.96875\n",
      "准确度为0.9375.\n",
      "第600次：Loss：0.08283726871013641 ; Accuracy：0.984375\n",
      "第700次：Loss：0.19425137341022491 ; Accuracy：0.9375\n",
      "第800次：Loss：0.1694011092185974 ; Accuracy：0.953125\n",
      "第900次：Loss：0.0904674381017685 ; Accuracy：0.984375\n",
      "第1000次：Loss：0.05042215436697006 ; Accuracy：0.984375\n",
      "准确度为1.0.\n",
      "第1100次：Loss：0.12709277868270874 ; Accuracy：0.953125\n",
      "第1200次：Loss：0.08249735832214355 ; Accuracy：0.984375\n",
      "第1300次：Loss：0.05995398759841919 ; Accuracy：0.96875\n",
      "第1400次：Loss：0.010672450065612793 ; Accuracy：1.0\n",
      "第1500次：Loss：0.03863348439335823 ; Accuracy：1.0\n",
      "准确度为1.0.\n"
     ]
    }
   ],
   "source": [
    "class LeNet_simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_simple,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # (N=64,C=1,H=28,W=28)\n",
    "            nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3,padding=1),\n",
    "            # (N=64,C=6,H=28,W=28)\n",
    "            nn.MaxPool2d(2,2)\n",
    "            # (N=64,C=6,H=14,W=14)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,padding=0),\n",
    "            # (N=64,C=16,H=10,W=10)\n",
    "            nn.MaxPool2d(2,2)\n",
    "            # (N=64,C=16,H=5,W=5)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(400,120),\n",
    "            nn.Linear(120,84),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def Accuracy(out,labels):\n",
    "    correct=0.0\n",
    "    total=0.0\n",
    "    _,predicted = torch.max(out.data, 1)\n",
    "    correct += (predicted==labels).sum()\n",
    "    total += labels.size(0)\n",
    "    accuracy = correct/total\n",
    "    return accuracy\n",
    "\n",
    "    \n",
    "########k折划分############        \n",
    "# def get_k_fold_data(k, i, X, y):\n",
    "#     assert k > 1\n",
    "#     fold_size = X.shape[0] // k  # 每份的个数\n",
    "    \n",
    "#     X_train, y_train = None, None\n",
    "#     for j in range(k):\n",
    "#         idx = slice(j * fold_size, (j + 1) * fold_size)  #slice(start,end,step)切片函数\n",
    "#         ##idx 为每组 valid\n",
    "#         X_part, y_part = X[idx, :], y[idx]\n",
    "#         if j == i: ###第i折作valid\n",
    "#             X_valid, y_valid = X_part, y_part\n",
    "#         elif X_train is None:\n",
    "#             X_train, y_train = X_part, y_part\n",
    "#         else:\n",
    "#             X_train = torch.cat((X_train, X_part), dim=0) #dim=0增加行数，竖着连接\n",
    "#             y_train = torch.cat((y_train, y_part), dim=0)\n",
    "#     return X_train, y_train, X_valid,y_valid\n",
    "\n",
    "\n",
    "########k折划分-mini_batch############        \n",
    "# def get_k_fold_data(k, i, X, y):\n",
    "#     assert k > 1\n",
    "#     X=X.numpy()\n",
    "#     fold_size = X.shape[0] // k  # 每份的个数\n",
    "    \n",
    "#     X_train = None\n",
    "#     for j in range(k):\n",
    "#         idx = slice(j * fold_size, (j + 1) * fold_size)  #slice(start,end,step)切片函数\n",
    "#         ##idx 为每组 valid\n",
    "#         X_part = X[idx, :]\n",
    "#         if j == i: ###第i折作valid\n",
    "#             X_valid = X_part\n",
    "#         elif X_train is None:\n",
    "#             X_train = X_part\n",
    "#         else:\n",
    "#             X_train = torch.cat((X_train, X_part), dim=0) #dim=0增加行数，竖着连接\n",
    "#     return torch.tensor(X_train), torch.tensor(X_valid)\n",
    "    \n",
    "net = LeNet_simple()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001,betas=(0.9,0.99)) #lr学习速率\n",
    "\n",
    "i=0\n",
    "for epoch in range(3):\n",
    "#     train, valid = get_k_fold_data(10,epoch,train_data,None)\n",
    "    train_loss=[]\n",
    "    accuracy=0.\n",
    "    correct=0.\n",
    "    total=0.\n",
    "    \n",
    "    for mini_batch,labels in train_data:\n",
    "        \"\"\"训练\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        out = net(mini_batch)\n",
    "        loss = criterion(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 输出信息\n",
    "        i+=1\n",
    "        accuracy=Accuracy(out,labels)\n",
    "        if i%100==0:\n",
    "            print(\"第{}次：Loss：{} ; Accuracy：{}\".format(i,loss,accuracy))\n",
    "            train_loss.append((i,loss))\n",
    "    \n",
    "    for mini_batch,labels in val_data:\n",
    "        \"\"\"验证\"\"\"\n",
    "        with torch.no_grad():\n",
    "            val_out = net(mini_batch)\n",
    "            val_loss = criterion(val_out,labels)\n",
    "            accuracy=Accuracy(val_out,labels)\n",
    "                \n",
    "    print(\"准确度为{}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ImageId  Label\n",
      "0            1      2\n",
      "1            2      0\n",
      "2            3      9\n",
      "3            4      9\n",
      "4            5      3\n",
      "...        ...    ...\n",
      "27995    27996      9\n",
      "27996    27997      7\n",
      "27997    27998      3\n",
      "27998    27999      9\n",
      "27999    28000      2\n",
      "\n",
      "[28000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "id=1\n",
    "image_id=[]\n",
    "result=[]\n",
    "\n",
    "for mini_batch in test_data:\n",
    "    \"\"\"测试\"\"\"\n",
    "    test_out = net(mini_batch)\n",
    "    _,predicted = torch.max(test_out.data, 1)\n",
    "    predicted=predicted.tolist()\n",
    "    result.extend(predicted)\n",
    "    for i in predicted:\n",
    "        image_id.append(id)\n",
    "        id+=1\n",
    "\n",
    "csv=pd.DataFrame({'ImageId':image_id,'Label':result})\n",
    "print(csv)\n",
    "csv.to_csv('predcit1.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
