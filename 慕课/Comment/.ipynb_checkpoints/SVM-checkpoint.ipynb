{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Sep  4 16:58:16 2018\n",
    "支持向量机代码实现\n",
    "SMO(Sequential Minimal Optimization)最小序列优化\n",
    "@author: weixw\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "#核转换函数（一个特征空间映射到另一个特征空间，低维空间映射到高维空间）\n",
    "#高维空间解决线性问题，低维空间解决非线性问题\n",
    "#线性内核 = 原始数据矩阵（100*2）与原始数据第一行矩阵转秩乘积（2*1） =>（100*1）\n",
    "#非线性内核公式：k(x,y) = exp(-||x - y||**2/2*(e**2))\n",
    "#1.原始数据每一行与原始数据第一行作差， \n",
    "#2.平方   \n",
    "def kernelTrans(dataMat, rowDataMat, kTup):\n",
    "    m,n=np.shape(dataMat)\n",
    "    #初始化核矩阵 m*1\n",
    "    K = np.mat(np.zeros((m,1)))\n",
    "    if kTup[0] == 'lin': #线性核\n",
    "        K = dataMat*rowDataMat.T\n",
    "    elif kTup[0] == 'rbf':#非线性核\n",
    "        for j in range(m):\n",
    "            #xi - xj\n",
    "            deltaRow = dataMat[j,:] - rowDataMat\n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        #1*m m*1 => 1*1\n",
    "        K = np.exp(K/(-2*kTup[1]**2))\n",
    "    else: raise NameError('Houston We Have a Problem -- That Kernel is not recognized')\n",
    "    return K\n",
    "        \n",
    "#定义数据结构体，用于缓存，提高运行速度\n",
    "class optStruct:\n",
    "    def __init__(self, dataSet, labelSet, C, toler, kTup):\n",
    "        self.dataMat = np.mat(dataSet) #原始数据，转换成m*n矩阵\n",
    "        self.labelMat = np.mat(labelSet).T #标签数据 m*1矩阵\n",
    "        self.C = C #惩罚参数，C越大，容忍噪声度小，需要优化；反之，容忍噪声度高，不需要优化；\n",
    "                   #所有的拉格朗日乘子都被限制在了以C为边长的矩形里\n",
    "        self.toler = toler #容忍度\n",
    "        self.m = np.shape(self.dataMat)[0] #原始数据行长度\n",
    "        self.alphas = np.mat(np.zeros((self.m,1))) # alpha系数，m*1矩阵\n",
    "        self.b = 0 #偏置\n",
    "        self.eCache = np.mat(np.zeros((self.m,2))) # 保存原始数据每行的预测值\n",
    "        self.K = np.mat(np.zeros((self.m,self.m))) # 核转换矩阵 m*m\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernelTrans(self.dataMat, self.dataMat[i,:], kTup)\n",
    "            \n",
    "#计算原始数据第k项对应的预测误差  1*m m*1 =>1*1  \n",
    "#oS：结构数据\n",
    "#k： 原始数据行索引           \n",
    "def calEk(oS, k):\n",
    "    #f(x) = w*x + b \n",
    "    fXk = float(np.multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "\n",
    "#在alpha有改变都要更新缓存\n",
    "def updateEk(oS, k):\n",
    "    Ek = calEk(oS, k)\n",
    "    oS.eCache[k] = [1, Ek]\n",
    "    \n",
    "\n",
    "#第一次通过selectJrand()随机选取j,之后选取与i对应预测误差最大的j（步长最大）\n",
    "def selectJ(i, oS, Ei):\n",
    "    #初始化\n",
    "    maxK = -1  #误差最大时对应索引\n",
    "    maxDeltaE = 0 #最大误差\n",
    "    Ej = 0 # j索引对应预测误差\n",
    "    #保存每一行的预测误差值 1相对于初始化为0的更改\n",
    "    oS.eCache[i] = [1,Ei]\n",
    "    #获取数据缓存结构中非0的索引列表(先将矩阵第0列转化为数组)\n",
    "    validEcacheList = np.nonzero(oS.eCache[:,0].A)[0]\n",
    "    #遍历索引列表，寻找最大误差对应索引\n",
    "    if len(validEcacheList) > 1:\n",
    "        for k in validEcacheList:\n",
    "            if k == i:\n",
    "                continue\n",
    "            Ek = calEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if(deltaE > maxDeltaE):\n",
    "                maxK = k\n",
    "                maxDeltaE = deltaE\n",
    "                Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:\n",
    "        #随机选取一个不等于i的j\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calEk(oS, j)\n",
    "    return j,Ej\n",
    "\n",
    "#随机选取一个不等于i的索引          \n",
    "def selectJrand(i, m):\n",
    "    j = i\n",
    "    while (j == i):\n",
    "        j = int(np.random.uniform(0, m))\n",
    "    return j\n",
    "\n",
    "#alpha范围剪辑\n",
    "def clipAlpha(aj, L, H):\n",
    "    if aj > H:\n",
    "        aj = H\n",
    "    if aj < L:\n",
    "        aj = L\n",
    "    return aj\n",
    "\n",
    "#从文件获取特征数据，标签数据\n",
    "def loadDataSet(fileName):\n",
    "#     dataSet = []; labelSet = []\n",
    "#     fr = open(fileName)\n",
    "#     for line in fr.readlines():\n",
    "#         #分割\n",
    "#         lineArr =  line.strip().split()\n",
    "#         dataSet.append([float(lineArr[0]), float(lineArr[1])])\n",
    "#         labelSet.append(float(lineArr[2]))\n",
    "#     return dataSet, labelSet\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    X = X[y<2, :2]\n",
    "    y = y[y<2]\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 0:\n",
    "            y[i] = -1\n",
    "    print(y)\n",
    "    return X,y\n",
    "\n",
    "#计算 w 权重系数\n",
    "def calWs(alphas, dataSet, labelSet):\n",
    "    dataMat = np.mat(dataSet)\n",
    "    #1*100 => 100*1\n",
    "    labelMat = np.mat(labelSet).T\n",
    "    m, n = np.shape(dataMat)    \n",
    "    w = np.zeros((n, 1))    \n",
    "    for i in range(m):\n",
    "        w += np.multiply(alphas[i]*labelMat[i], dataMat[i,:].T)        \n",
    "    return w\n",
    "#计算原始数据每一行alpha,b，保存到数据结构中，有变化及时更新       \n",
    "def innerL(i, oS):\n",
    "    #计算预测误差\n",
    "    Ei = calEk(oS, i)\n",
    "    #选择第一个alpha，违背KKT条件2\n",
    "    #正间隔，负间隔\n",
    "    if ((oS.labelMat[i] * Ei < -oS.toler) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i] * Ei > oS.toler) and (oS.alphas[i] > 0)):\n",
    "        #第一次随机选取不等于i的数据项，其后根据误差最大选取数据项\n",
    "        j, Ej = selectJ(i, oS, Ei)\n",
    "        #初始化，开辟新的内存\n",
    "        alphaIold = oS.alphas[i].copy()\n",
    "        alphaJold = oS.alphas[j].copy()\n",
    "        #通过 a1y1 + a2y2 = 常量\n",
    "        #    0 <= a1,a2 <= C 求出L,H\n",
    "        if oS.labelMat[i] != oS.labelMat[j]:\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L == H : \n",
    "            print (\"L == H\")\n",
    "            return 0\n",
    "        #内核分母 K11 + K22 - 2K12\n",
    "        eta = oS.K[i, i] + oS.K[j, j] - 2.0*oS.K[i, j]\n",
    "        if eta <= 0:\n",
    "            print (\"eta <= 0\")\n",
    "            return 0\n",
    "        #计算第一个alpha j\n",
    "        oS.alphas[j] += oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        #修正alpha j的范围\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j], L, H)\n",
    "        #alpha有改变，就需要更新缓存数据\n",
    "        updateEk(oS, j)\n",
    "        #如果优化后的alpha 与之前的alpha变化很小，则舍弃，并重新选择数据项的alpha\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            print (\"j not moving enough, abandon it.\")\n",
    "            return 0\n",
    "        #计算alpha对的另一个alpha i\n",
    "        # ai_new*yi + aj_new*yj = 常量\n",
    "        # ai_old*yi + ai_old*yj = 常量 \n",
    "        # 作差=> ai = ai_old + yi*yj*(aj_old - aj_new)\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])\n",
    "        #alpha有改变，就需要更新缓存数据\n",
    "        updateEk(oS, i)\n",
    "        #计算b1,b2\n",
    "        # y(x) = w*x + b => b = y(x) - w*x\n",
    "        # w = aiyixi(i= 1->N求和)\n",
    "        #b1_new = y1_new - (a1_new*y1*k11 + a2_new*y2*k21 + ai*yi*ki1(i = 3 ->N求和 常量))\n",
    "        #b1_old = y1_old - (a1_old*y1*k11 + a2_old*y2*k21 + ai*yi*ki1(i = 3 ->N求和 常量))\n",
    "        #作差=> b1_new = b1_old + (y1_new - y1_old) - y1*k11*(a1_new - a1_old) - y2*k21*(a2_new - a2_old)\n",
    "        # => b1_new = b1_old + Ei - yi*(ai_new - ai_old)*kii - yj*(aj_new - aj_old)*kij      \n",
    "        #同样可推得 b2_new = b2_old + Ej - yi*(ai_new - ai_old)*kij - yj*(aj_new - aj_old)*kjj\n",
    "        bi = oS.b - Ei - oS.labelMat[i]*(oS.alphas[i] - alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j] - alphaJold)*oS.K[i,j]\n",
    "        bj = oS.b - Ej - oS.labelMat[i]*(oS.alphas[i] - alphaIold)*oS.K[i,j] - oS.labelMat[j]*(oS.alphas[j] - alphaJold)*oS.K[j,j]\n",
    "        #首选alpha i，相对alpha j 更准确\n",
    "        if (0 < oS.alphas[i]) and (oS.alphas[i] < oS.C):\n",
    "            oS.b = bi\n",
    "        elif (0 < oS.alphas[j]) and (oS.alphas[j] < oS.C):\n",
    "            oS.b = bj\n",
    "        else:\n",
    "            oS.b = (bi + bj)/2.0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#完整SMO核心算法，包含线性核核非线性核，返回alpha,b\n",
    "#dataSet 原始特征数据\n",
    "#labelSet 标签数据\n",
    "#C 凸二次规划参数\n",
    "#toler 容忍度\n",
    "#maxInter 循环次数\n",
    "#kTup 指定核方式\n",
    "#程序逻辑：\n",
    "#第一次全部遍历，遍历后根据alpha对是否有修改判断，\n",
    "#如果alpha对没有修改，外循环终止；如果alpha对有修改，则继续遍历属于支持向量的数据。\n",
    "#直至外循环次数达到maxIter\n",
    "#相比简单SMO算法，运行速度更快，原因是：\n",
    "#1.不是每一次都全量遍历原始数据，第一次遍历原始数据，\n",
    "#如果alpha有优化，就遍历支持向量数据，直至alpha没有优化，然后再转全量遍历，这是如果alpha没有优化，循环结束；\n",
    "#2.外循环不需要达到maxInter次数就终止；\n",
    "def smoP(dataSet, labelSet, C, toler, maxInter, kTup = ('lin', 0)):\n",
    "    #初始化结构体类，获取实例\n",
    "    oS = optStruct(dataSet, labelSet, C, toler, kTup)\n",
    "    iter = 0\n",
    "    #全量遍历标志\n",
    "    entireSet = True\n",
    "    #alpha对是否优化标志\n",
    "    alphaPairsChanged = 0\n",
    "    #外循环 终止条件：1.达到最大次数 或者 2.alpha对没有优化\n",
    "    while (iter < maxInter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        alphaPairsChanged = 0\n",
    "        #全量遍历 ，遍历每一行数据 alpha对有修改，alphaPairsChanged累加\n",
    "        if entireSet:\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print (\"fullSet, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        else:\n",
    "            #获取(0，C)范围内数据索引列表，也就是只遍历属于支持向量的数据\n",
    "            nonBounds = np.nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBounds:\n",
    "                alphaPairsChanged += innerL(i, oS)\n",
    "                print (\"non-bound, iter: %d i:%d, pairs changed %d\" %(iter, i, alphaPairsChanged))\n",
    "            iter += 1\n",
    "        #全量遍历->支持向量遍历\n",
    "        if entireSet:\n",
    "            entireSet = False\n",
    "        #支持向量遍历->全量遍历\n",
    "        elif alphaPairsChanged == 0:\n",
    "            entireSet = True\n",
    "        print (\"iteation number: %d\"% iter)\n",
    "        print (\"entireSet :%s\"% entireSet)\n",
    "        print (\"alphaPairsChanged :%d\"% alphaPairsChanged)\n",
    "    return oS.b,oS.alphas\n",
    "\n",
    "#绘制支持向量\n",
    "def drawDataMap(dataArr,labelArr,b,alphas):\n",
    "    import matplotlib.pyplot as plt\n",
    "    #alphas.A>0 获取大于0的索引列表，只有>0的alpha才对分类起作用\n",
    "    svInd=np.nonzero(alphas.A>0)[0]           \n",
    "     #分类数据点\n",
    "    classified_pts = {'+1':[],'-1':[]}\n",
    "    for point,label in zip(dataArr,labelArr):\n",
    "        if label == 1.0:\n",
    "            classified_pts['+1'].append(point)\n",
    "        else:\n",
    "            classified_pts['-1'].append(point)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    #绘制数据点\n",
    "    for label,pts in classified_pts.items():\n",
    "        pts = np.array(pts)\n",
    "        ax.scatter(pts[:, 0], pts[:, 1], label = label)\n",
    "    #绘制分割线\n",
    "    w = calWs(alphas, dataArr, labelArr)\n",
    "    #函数形式：max( x ,key=lambda a : b )        #    x可以是任何数值，可以有多个x值\n",
    "    #先把x值带入lambda函数转换成b值，然后再将b值进行比较\n",
    "    x1, _=max(dataArr, key=lambda x:x[0])\n",
    "    x2, _=min(dataArr, key=lambda x:x[0])    \n",
    "    a1, a2 = w\n",
    "    y1, y2 = (-b - a1*x1)/a2, (-b - a1*x2)/a2\n",
    "    #矩阵转化为数组.A\n",
    "    ax.plot([x1, x2],[y1.A[0][0], y2.A[0][0]])\n",
    "    \n",
    "    #绘制支持向量\n",
    "    for i in svInd:\n",
    "        x, y= dataArr[i]        \n",
    "        ax.scatter([x], [y], s=150, c ='none', alpha=0.7, linewidth=1.5, edgecolor = '#AB3319')\n",
    "    plt.show()\n",
    "    \n",
    "     #alpha>0对应的数据才是支持向量，过滤不是支持向量的数据\n",
    "    sVs= np.mat(dataArr)[svInd] #get matrix of only support vectors\n",
    "    print (\"there are %d Support Vectors.\\n\" % np.shape(sVs)[0])\n",
    "    \n",
    "#训练结果    \n",
    "def getTrainingDataResult(dataSet, labelSet, b, alphas, k1=1.3):\n",
    "    datMat = np.mat(dataSet)\n",
    "    #100*1\n",
    "    labelMat = np.mat(labelSet).T\n",
    "    #alphas.A>0 获取大于0的索引列表，只有>0的alpha才对分类起作用\n",
    "    svInd=np.nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd]\n",
    "    labelSV = labelMat[svInd];\n",
    "    m,n = np.shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        # y(x) = w*x + b => b = y(x) - w*x\n",
    "        # w = aiyixi(i= 1->N求和)\n",
    "        predict = kernelEval.T * np.multiply(labelSV, alphas[svInd]) + b\n",
    "        if np.sign(predict)!=np.sign(labelSet[i]): errorCount += 1\n",
    "    print (\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    \n",
    "def getTestDataResult(dataSet, labelSet, b, alphas, k1=1.3):\n",
    "    datMat = np.mat(dataSet)\n",
    "    #100*1\n",
    "    labelMat = np.mat(labelSet).T\n",
    "    #alphas.A>0 获取大于0的索引列表，只有>0的alpha才对分类起作用\n",
    "    svInd=np.nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd]\n",
    "    labelSV = labelMat[svInd];\n",
    "    m,n = np.shape(datMat)\n",
    "    errorCount = 0\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        # y(x) = w*x + b => b = y(x) - w*x\n",
    "        # w = aiyixi(i= 1->N求和)\n",
    "        predict=kernelEval.T * np.multiply(labelSV,alphas[svInd]) + b\n",
    "#         print(\"{}  {}\".format(predict,np.sign(predict)))\n",
    "        if np.sign(predict)!=np.sign(labelSet[i]): errorCount += 1    \n",
    "    print (\"the test error rate is: %f\" % (float(errorCount)/m))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-6320958f6e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#通过训练数据计算 b, alphas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataArr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trainingData.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmoP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrawDataMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelArr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgetTrainingDataResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-7c388cd016f9>\u001b[0m in \u001b[0;36mloadDataSet\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;31m#         labelSet.append(float(lineArr[2]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m#     return dataSet, labelSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_iris\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "#通过训练数据计算 b, alphas\n",
    "dataArr,labelArr = loadDataSet('trainingData.txt')\n",
    "b, alphas = smoP(dataArr, labelArr, 200, 0.0001, 10000, ('rbf', 0.10))\n",
    "drawDataMap(dataArr,labelArr,b,alphas)\n",
    "getTrainingDataResult(dataArr, labelArr, b, alphas, 0.10)\n",
    "dataArr1,labelArr1 = loadDataSet('testData.txt')\n",
    "#测试结果\n",
    "getTestDataResult(dataArr1, labelArr1, b, alphas, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-1.]]\n",
    "[[-1.]]\n",
    "[[-1.]]\n",
    "[[-1.]]\n",
    "[[1.]]\n",
    "[[1.]]\n",
    "[[1.]]\n",
    "[[-1.]]\n",
    "[[-1.]]\n",
    "[[-1.]]\n",
    "[[-1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.542485', '1.977398', '-1']\n",
      "['3.018896', '2.556416', '-1']\n",
      "['7.551510', '-1.580030', '1']\n",
      "['2.114999', '-0.004466', '-1']\n",
      "['8.127113', '1.274372', '1']\n",
      "['7.108772', '-0.986906', '1']\n",
      "['8.610639', '2.046708', '1']\n",
      "['2.326297', '0.265213', '-1']\n",
      "['3.634009', '1.730537', '-1']\n",
      "['0.341367', '-0.894998', '-1']\n",
      "['3.125951', '0.293251', '-1']\n",
      "['2.123252', '-0.783563', '-1']\n",
      "['0.887835', '-2.797792', '-1']\n",
      "['7.139979', '-2.329896', '1']\n",
      "['1.696414', '-1.212496', '-1']\n",
      "['8.117032', '0.623493', '1']\n",
      "['8.497162', '-0.266649', '1']\n",
      "['4.658191', '3.507396', '-1']\n",
      "['8.197181', '1.545132', '1']\n",
      "['1.208047', '0.213100', '-1']\n",
      "['1.928486', '-0.321870', '-1']\n",
      "['2.175808', '-0.014527', '-1']\n",
      "['7.886608', '0.461755', '1']\n",
      "['3.223038', '-0.552392', '-1']\n",
      "['3.628502', '2.190585', '-1']\n",
      "['7.407860', '-0.121961', '1']\n",
      "['7.286357', '0.251077', '1']\n",
      "['2.301095', '-0.533988', '-1']\n",
      "['-0.232542', '-0.547690', '-1']\n",
      "['3.457096', '-0.082216', '-1']\n",
      "['3.023938', '-0.057392', '-1']\n",
      "['8.015003', '0.885325', '1']\n",
      "['8.991748', '0.923154', '1']\n",
      "['7.916831', '-1.781735', '1']\n",
      "['7.616862', '-0.217958', '1']\n",
      "['2.450939', '0.744967', '-1']\n",
      "['7.270337', '-2.507834', '1']\n",
      "['1.749721', '-0.961902', '-1']\n",
      "['1.803111', '-0.176349', '-1']\n",
      "['8.804461', '3.044301', '1']\n",
      "['1.231257', '-0.568573', '-1']\n",
      "['2.074915', '1.410550', '-1']\n",
      "['-0.743036', '-1.736103', '-1']\n",
      "['3.536555', '3.964960', '-1']\n",
      "['8.410143', '0.025606', '1']\n",
      "['7.382988', '-0.478764', '1']\n",
      "['6.960661', '-0.245353', '1']\n",
      "['8.234460', '0.701868', '1']\n",
      "['8.168618', '-0.903835', '1']\n",
      "['1.534187', '-0.622492', '-1']\n",
      "['9.229518', '2.066088', '1']\n",
      "['7.886242', '0.191813', '1']\n",
      "['2.893743', '-1.643468', '-1']\n",
      "['1.870457', '-1.040420', '-1']\n",
      "['5.286862', '-2.358286', '1']\n",
      "['6.080573', '0.418886', '1']\n",
      "['2.544314', '1.714165', '-1']\n",
      "['6.016004', '-3.753712', '1']\n",
      "['0.926310', '-0.564359', '-1']\n",
      "['0.870296', '-0.109952', '-1']\n",
      "['2.369345', '1.375695', '-1']\n",
      "['1.363782', '-0.254082', '-1']\n",
      "['7.279460', '-0.189572', '1']\n",
      "['1.896005', '0.515080', '-1']\n",
      "['8.102154', '-0.603875', '1']\n",
      "['2.529893', '0.662657', '-1']\n",
      "['1.963874', '-0.365233', '-1']\n",
      "['8.132048', '0.785914', '1']\n",
      "['8.245938', '0.372366', '1']\n",
      "['6.543888', '0.433164', '1']\n",
      "['-0.236713', '-5.766721', '-1']\n",
      "['8.112593', '0.295839', '1']\n",
      "['9.803425', '1.495167', '1']\n",
      "['1.497407', '-0.552916', '-1']\n",
      "['1.336267', '-1.632889', '-1']\n",
      "['9.205805', '-0.586480', '1']\n",
      "['1.966279', '-1.840439', '-1']\n",
      "['8.398012', '1.584918', '1']\n",
      "['7.239953', '-1.764292', '1']\n",
      "['7.556201', '0.241185', '1']\n",
      "['9.015509', '0.345019', '1']\n",
      "['8.266085', '-0.230977', '1']\n",
      "['8.545620', '2.788799', '1']\n",
      "['9.295969', '1.346332', '1']\n",
      "['2.404234', '0.570278', '-1']\n",
      "['2.037772', '0.021919', '-1']\n",
      "['1.727631', '-0.453143', '-1']\n",
      "['1.979395', '-0.050773', '-1']\n",
      "['8.092288', '-1.372433', '1']\n",
      "['1.667645', '0.239204', '-1']\n",
      "['9.854303', '1.365116', '1']\n",
      "['7.921057', '-1.327587', '1']\n",
      "['8.500757', '1.492372', '1']\n",
      "['1.339746', '-0.291183', '-1']\n",
      "['3.107511', '0.758367', '-1']\n",
      "['2.609525', '0.902979', '-1']\n",
      "['3.263585', '1.367898', '-1']\n",
      "['2.912122', '-0.202359', '-1']\n",
      "['1.731786', '0.589096', '-1']\n",
      "['2.387003', '1.573131', '-1']\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet(fileName):\n",
    "    dataSet = []; labelSet = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        #分割\n",
    "        lineArr =  line.strip().split()\n",
    "        print(lineArr)\n",
    "        dataSet.append([float(lineArr[0]), float(lineArr[1])])\n",
    "        labelSet.append(float(lineArr[2]))\n",
    "    return dataSet, labelSet\n",
    "dataArr,labelArr = loadDataSet('testData.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
